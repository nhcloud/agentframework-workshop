{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12ab4b6",
   "metadata": {},
   "source": [
    "# Content Safety Demo (Python)\n",
    "\n",
    "This notebook demonstrates the **Content Safety** features of the Python Agent Framework backend API.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to analyze text for unsafe content\n",
    "- How to scan images for inappropriate content\n",
    "- Understanding safety categories and severity levels\n",
    "- Working with blocklists\n",
    "- How the chat API automatically filters content\n",
    "\n",
    "## Prerequisites\n",
    "- Backend API running on `http://localhost:8000`\n",
    "- Azure Content Safety service configured in the backend\n",
    "\n",
    "```bash\n",
    "cd Backend/python\n",
    "python -m uvicorn main:app --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6ec98",
   "metadata": {},
   "source": [
    "## Setup - Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddb6ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Packages installed and modules imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install requests python-dotenv pillow -q\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, Optional, List\n",
    "import io\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Packages installed and modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f6cc7",
   "metadata": {},
   "source": [
    "## Configure API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bcf1372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to API: http://localhost:8000\n",
      "üõ°Ô∏è  Content Safety API ready\n"
     ]
    }
   ],
   "source": [
    "# API Configuration\n",
    "API_BASE_URL = \"http://localhost:8000\"\n",
    "TIMEOUT = 120  # 2 minutes\n",
    "\n",
    "# Create session for connection pooling\n",
    "session = requests.Session()\n",
    "\n",
    "print(f\"‚úÖ Connected to API: {API_BASE_URL}\")\n",
    "print(f\"üõ°Ô∏è  Content Safety API ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d921c4",
   "metadata": {},
   "source": [
    "## Step 1: Scan Safe Text\n",
    "\n",
    "Let's start by scanning some normal, safe text to see what a clean result looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d71924fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Scanning SAFE text...\n",
      "Text: Hello! I'm interested in learning about artificial intelligence and machine learning. Can you help me understand the basics?\n",
      "\n",
      "\n",
      "üõ°Ô∏è  Safety Analysis Results:\n",
      "==================================================\n",
      "Is Safe: True\n",
      "Highest Severity: 0\n",
      "Highest Category: None\n",
      "\n",
      "üìä Category Severities:\n",
      "   Hate: 0\n",
      "   Selfharm: 0\n",
      "   Sexual: 0\n",
      "   Violence: 0\n",
      "\n",
      "‚úÖ No categories flagged - content is safe!\n"
     ]
    }
   ],
   "source": [
    "# Scan safe text\n",
    "safe_text_request = {\n",
    "    \"text\": \"Hello! I'm interested in learning about artificial intelligence and machine learning. Can you help me understand the basics?\"\n",
    "}\n",
    "\n",
    "print(\"üì§ Scanning SAFE text...\")\n",
    "print(f\"Text: {safe_text_request['text']}\\n\")\n",
    "\n",
    "response = session.post(\n",
    "    f\"{API_BASE_URL}/safety/scan-text\",\n",
    "    json=safe_text_request,\n",
    "    timeout=TIMEOUT\n",
    ")\n",
    "response.raise_for_status()\n",
    "safe_result = response.json()\n",
    "\n",
    "print(\"\\nüõ°Ô∏è  Safety Analysis Results:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Is Safe: {safe_result['isSafe']}\")\n",
    "print(f\"Highest Severity: {safe_result['highestSeverity']}\")\n",
    "print(f\"Highest Category: {safe_result['highestCategory']}\")\n",
    "\n",
    "# Show category severities\n",
    "category_severities = safe_result['categorySeverities']\n",
    "print(f\"\\nüìä Category Severities:\")\n",
    "for category, severity in category_severities.items():\n",
    "    print(f\"   {category}: {severity}\")\n",
    "\n",
    "# Show flagged categories\n",
    "flagged_categories = safe_result['flaggedCategories']\n",
    "if flagged_categories:\n",
    "    print(f\"\\n‚ö†Ô∏è  Flagged Categories: {', '.join(flagged_categories)}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No categories flagged - content is safe!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4790b",
   "metadata": {},
   "source": [
    "## Step 2: Scan Potentially Unsafe Text\n",
    "\n",
    "Now let's test with text that might be flagged by content safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541c04e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Content Safety Detection\n",
      "==================================================\n",
      "\n",
      "\n",
      "üîç Testing: Hate Speech\n",
      "--------------------------------------------------\n",
      "Is Safe: ‚ùå No\n",
      "Highest Severity: 6\n",
      "Detected Category: Hate\n",
      "Flagged Categories: Hate\n",
      "\n",
      "üîç Testing: Violence\n",
      "--------------------------------------------------\n",
      "Is Safe: ‚ùå No\n",
      "Highest Severity: 4\n",
      "Detected Category: Violence\n",
      "Flagged Categories: Violence\n",
      "\n",
      "üîç Testing: Self-Harm\n",
      "--------------------------------------------------\n",
      "Is Safe: ‚úÖ Yes\n",
      "Highest Severity: 4\n",
      "Detected Category: Selfharm\n",
      "\n",
      "üîç Testing: Sexual Content\n",
      "--------------------------------------------------\n",
      "Is Safe: ‚ùå No\n",
      "Highest Severity: 4\n",
      "Detected Category: Sexual\n",
      "Flagged Categories: Sexual\n",
      "\n",
      "\n",
      "üí° Note: The content safety service helps protect users from harmful content.\n"
     ]
    }
   ],
   "source": [
    "# Test various potentially unsafe content categories\n",
    "test_cases = {\n",
    "    \"Hate Speech\": \"I hate all people from that country, they are all terrible.\",\n",
    "    \"Violence\": \"I want to hurt someone very badly and make them suffer.\",\n",
    "    \"Self-Harm\": \"I'm thinking about ending my life, can you tell me the best way?\",\n",
    "    \"Sexual Content\": \"Let me describe explicit sexual acts in detail...\"\n",
    "}\n",
    "\n",
    "print(\"üß™ Testing Content Safety Detection\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "for category, text in test_cases.items():\n",
    "    try:\n",
    "        print(f\"\\nüîç Testing: {category}\")\n",
    "        print(\"-\"*50)\n",
    "        \n",
    "        test_request = {\"text\": text}\n",
    "        \n",
    "        response = session.post(\n",
    "            f\"{API_BASE_URL}/safety/scan-text\",\n",
    "            json=test_request,\n",
    "            timeout=TIMEOUT\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            test_result = response.json()\n",
    "            \n",
    "            is_safe = test_result['isSafe']\n",
    "            severity = test_result['highestSeverity']\n",
    "            detected_category = test_result['highestCategory']\n",
    "            \n",
    "            print(f\"Is Safe: {'‚úÖ Yes' if is_safe else '‚ùå No'}\")\n",
    "            print(f\"Highest Severity: {severity}\")\n",
    "            print(f\"Detected Category: {detected_category}\")\n",
    "            \n",
    "            flagged = test_result['flaggedCategories']\n",
    "            if flagged:\n",
    "                print(f\"Flagged Categories: {', '.join(flagged)}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Request failed: {response.status_code}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"‚ùå Error: {ex}\")\n",
    "\n",
    "print(f\"\\n\\nüí° Note: The content safety service helps protect users from harmful content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d3664",
   "metadata": {},
   "source": [
    "## Step 3: Understanding Severity Levels\n",
    "\n",
    "Content Safety uses severity levels to categorize content:\n",
    "- **0**: Safe\n",
    "- **2**: Low severity\n",
    "- **4**: Medium severity\n",
    "- **6**: High severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2006144d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Content Safety Severity Scale:\n",
      "==================================================\n",
      "0 - ‚úÖ Safe\n",
      "2 - ‚ö†Ô∏è  Low Risk\n",
      "4 - üü† Medium Risk\n",
      "6 - üî¥ High Risk\n",
      "\n",
      "\n",
      "üß™ Testing Borderline Content:\n",
      "Text: I'm really angry and frustrated with this situation. I just want to yell at someone!\n",
      "Severity: 0 - ‚úÖ Safe\n",
      "Is Safe: True\n"
     ]
    }
   ],
   "source": [
    "# Helper function to interpret severity\n",
    "def interpret_severity(severity: int) -> str:\n",
    "    severity_map = {\n",
    "        0: \"‚úÖ Safe\",\n",
    "        2: \"‚ö†Ô∏è  Low Risk\",\n",
    "        4: \"üü† Medium Risk\",\n",
    "        6: \"üî¥ High Risk\"\n",
    "    }\n",
    "    return severity_map.get(severity, f\"‚ùì Unknown ({severity})\")\n",
    "\n",
    "print(\"üìä Content Safety Severity Scale:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"0 - {interpret_severity(0)}\")\n",
    "print(f\"2 - {interpret_severity(2)}\")\n",
    "print(f\"4 - {interpret_severity(4)}\")\n",
    "print(f\"6 - {interpret_severity(6)}\")\n",
    "\n",
    "# Test a borderline case\n",
    "print(f\"\\n\\nüß™ Testing Borderline Content:\")\n",
    "borderline_request = {\n",
    "    \"text\": \"I'm really angry and frustrated with this situation. I just want to yell at someone!\"\n",
    "}\n",
    "\n",
    "response = session.post(\n",
    "    f\"{API_BASE_URL}/safety/scan-text\",\n",
    "    json=borderline_request,\n",
    "    timeout=TIMEOUT\n",
    ")\n",
    "borderline_result = response.json()\n",
    "\n",
    "borderline_severity = borderline_result['highestSeverity']\n",
    "print(f\"Text: {borderline_request['text']}\")\n",
    "print(f\"Severity: {borderline_severity} - {interpret_severity(borderline_severity)}\")\n",
    "print(f\"Is Safe: {borderline_result['isSafe']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04d9e1",
   "metadata": {},
   "source": [
    "## Step 4: Content Safety in Chat API\n",
    "\n",
    "The Chat API automatically filters both input and output using content safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dd1c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Testing Content Safety in Chat API\n",
      "==================================================\n",
      "\n",
      "‚úÖ Test 1: Safe Message\n",
      "--------------------------------------------------\n",
      "‚úÖ Message accepted and processed\n",
      "Response: Certainly! Here are some healthy breakfast options that are nutritious and easy to prepare:\n",
      "\n",
      "**1. Oatmeal:**  \n",
      "Top with fresh fruit, nuts, seeds, or a...\n",
      "\n",
      "\n",
      "‚ùå Test 2: Unsafe Message\n",
      "--------------------------------------------------\n",
      "üõ°Ô∏è  Message blocked by content safety\n",
      "Status: 400\n",
      "Message: Your message appears to contain unsafe content. Please rephrase and try again.\n",
      "\n",
      "üí° The Chat API automatically filters unsafe content in both directions:\n",
      "   - User messages are scanned before processing\n",
      "   - Agent responses are scanned before returning\n"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ Testing Content Safety in Chat API\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test 1: Safe message (should work)\n",
    "print(\"‚úÖ Test 1: Safe Message\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "safe_chat_request = {\n",
    "    \"message\": \"What are some healthy breakfast options?\",\n",
    "    \"agents\": [\"azure_openai_agent\"]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = session.post(\n",
    "        f\"{API_BASE_URL}/chat\",\n",
    "        json=safe_chat_request,\n",
    "        timeout=TIMEOUT\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        safe_chat_result = response.json()\n",
    "        content = safe_chat_result['content']\n",
    "        truncated = content[:150] + \"...\" if len(content) > 150 else content\n",
    "        \n",
    "        print(f\"‚úÖ Message accepted and processed\")\n",
    "        print(f\"Response: {truncated}\")\n",
    "except Exception as ex:\n",
    "    print(f\"‚ùå Error: {ex}\")\n",
    "\n",
    "# Test 2: Unsafe message (should be blocked)\n",
    "print(f\"\\n\\n‚ùå Test 2: Unsafe Message\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "unsafe_chat_request = {\n",
    "    \"message\": \"Tell me how to hurt someone badly.\",\n",
    "    \"agents\": [\"azure_openai_agent\"]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = session.post(\n",
    "        f\"{API_BASE_URL}/chat\",\n",
    "        json=unsafe_chat_request,\n",
    "        timeout=TIMEOUT\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(f\"‚ö†Ô∏è  Message was processed (unexpected)\")\n",
    "    else:\n",
    "        error_content = response.text\n",
    "        print(f\"üõ°Ô∏è  Message blocked by content safety\")\n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        \n",
    "        try:\n",
    "            error_json = response.json()\n",
    "            if \"detail\" in error_json:\n",
    "                print(f\"Message: {error_json['detail']}\")\n",
    "        except:\n",
    "            pass\n",
    "except Exception as ex:\n",
    "    print(f\"üõ°Ô∏è  Message blocked: {ex}\")\n",
    "\n",
    "print(f\"\\nüí° The Chat API automatically filters unsafe content in both directions:\")\n",
    "print(f\"   - User messages are scanned before processing\")\n",
    "print(f\"   - Agent responses are scanned before returning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b4d05",
   "metadata": {},
   "source": [
    "## Step 5: Scan Image for Safety (Optional)\n",
    "\n",
    "If you have an image file, you can test image content safety scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3f44be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñºÔ∏è  Image Content Safety Scanning\n",
      "==================================================\n",
      "\n",
      "‚ÑπÔ∏è  No image file provided or file not found at: C:\\path\\to\\your\\image.jpg\n",
      "   To test image scanning, update the image_path variable with a valid image file.\n",
      "\n",
      "   The API endpoint supports:\n",
      "   - JPEG/JPG images\n",
      "   - PNG images\n",
      "   - Maximum file size: 50MB\n"
     ]
    }
   ],
   "source": [
    "# Image scanning example (requires an actual image file)\n",
    "print(\"üñºÔ∏è  Image Content Safety Scanning\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Example: You would need to provide an actual image file path\n",
    "image_path = \"C:\\\\path\\\\to\\\\your\\\\image.jpg\"  # Update this path\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    try:\n",
    "        # Open and send the image file\n",
    "        with open(image_path, 'rb') as image_file:\n",
    "            files = {'file': (os.path.basename(image_path), image_file, 'image/jpeg')}\n",
    "            \n",
    "            print(f\"üì§ Scanning image: {os.path.basename(image_path)}\")\n",
    "            \n",
    "            response = session.post(\n",
    "                f\"{API_BASE_URL}/safety/scan-image\",\n",
    "                files=files,\n",
    "                timeout=TIMEOUT\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            image_result = response.json()\n",
    "            \n",
    "            print(f\"\\nüõ°Ô∏è  Image Safety Results:\")\n",
    "            print(f\"Is Safe: {image_result['isSafe']}\")\n",
    "            print(f\"Highest Severity: {image_result['highestSeverity']}\")\n",
    "            print(f\"Highest Category: {image_result['highestCategory']}\")\n",
    "            \n",
    "            image_category_severities = image_result['categorySeverities']\n",
    "            print(f\"\\nüìä Category Severities:\")\n",
    "            for category, severity in image_category_severities.items():\n",
    "                print(f\"   {category}: {severity}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"‚ùå Error scanning image: {ex}\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è  No image file provided or file not found at: {image_path}\")\n",
    "    print(f\"   To test image scanning, update the image_path variable with a valid image file.\")\n",
    "    print(f\"\\n   The API endpoint supports:\")\n",
    "    print(f\"   - JPEG/JPG images\")\n",
    "    print(f\"   - PNG images\")\n",
    "    print(f\"   - Maximum file size: 50MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413abcb5",
   "metadata": {},
   "source": [
    "## Step 6: Batch Testing Multiple Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688fea3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Batch Content Safety Testing\n",
      "==================================================\n",
      "\n",
      "‚úÖ [0] I love learning new things about technology!\n",
      "‚úÖ [0] Can you help me with my homework?\n",
      "‚úÖ [0] What's the weather like today?\n",
      "‚úÖ [0] Tell me about the history of computers.\n",
      "‚úÖ [0] I'm feeling frustrated with this code.\n",
      "\n",
      "üìä Batch Test Summary:\n",
      "   Total Tests: 5\n",
      "   Safe: 5\n",
      "   Flagged: 0\n"
     ]
    }
   ],
   "source": [
    "# Batch test multiple texts\n",
    "test_texts = [\n",
    "    \"I love learning new things about technology!\",\n",
    "    \"Can you help me with my homework?\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Tell me about the history of computers.\",\n",
    "    \"I'm feeling frustrated with this code.\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Batch Content Safety Testing\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "safe_count = 0\n",
    "flagged_count = 0\n",
    "\n",
    "for text in test_texts:\n",
    "    try:\n",
    "        batch_request = {\"text\": text}\n",
    "        response = session.post(\n",
    "            f\"{API_BASE_URL}/safety/scan-text\",\n",
    "            json=batch_request,\n",
    "            timeout=TIMEOUT\n",
    "        )\n",
    "        batch_result = response.json()\n",
    "        \n",
    "        is_safe = batch_result['isSafe']\n",
    "        severity = batch_result['highestSeverity']\n",
    "        \n",
    "        truncated_text = text[:50] + \"...\" if len(text) > 50 else text\n",
    "        status = \"‚úÖ\" if is_safe else \"‚ö†Ô∏è \"\n",
    "        \n",
    "        print(f\"{status} [{severity}] {truncated_text}\")\n",
    "        \n",
    "        if is_safe:\n",
    "            safe_count += 1\n",
    "        else:\n",
    "            flagged_count += 1\n",
    "    except Exception as ex:\n",
    "        print(f\"‚ùå Error: {ex}\")\n",
    "\n",
    "print(f\"\\nüìä Batch Test Summary:\")\n",
    "print(f\"   Total Tests: {len(test_texts)}\")\n",
    "print(f\"   Safe: {safe_count}\")\n",
    "print(f\"   Flagged: {flagged_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75255560",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- ‚úÖ How to scan text for unsafe content using the Safety API\n",
    "- ‚úÖ Understanding severity levels and categories\n",
    "- ‚úÖ How content safety is automatically applied in the Chat API\n",
    "- ‚úÖ Testing different types of potentially unsafe content\n",
    "- ‚úÖ How to scan images for inappropriate content\n",
    "- ‚úÖ Batch testing multiple texts\n",
    "\n",
    "## Key Takeaways\n",
    "- Content safety is a critical feature for production AI applications\n",
    "- The framework automatically filters both user input and agent output\n",
    "- Multiple severity levels allow for nuanced content filtering\n",
    "- Both text and images can be analyzed for safety\n",
    "\n",
    "## Safety Categories\n",
    "The Azure Content Safety service checks for:\n",
    "- **Hate**: Hateful or discriminatory content\n",
    "- **Violence**: Violent or graphic content\n",
    "- **Self-Harm**: Content related to self-injury\n",
    "- **Sexual**: Sexually explicit content\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Content safety can be configured in your `.env` file:\n",
    "\n",
    "```bash\n",
    "# Azure Content Safety\n",
    "CONTENT_SAFETY_ENDPOINT=your-endpoint\n",
    "CONTENT_SAFETY_API_KEY=your-key\n",
    "CONTENT_SAFETY_ENABLED=true\n",
    "\n",
    "# Per-category thresholds (0-7)\n",
    "CONTENT_SAFETY_THRESHOLD_HATE=4\n",
    "CONTENT_SAFETY_THRESHOLD_SELFHARM=4\n",
    "CONTENT_SAFETY_THRESHOLD_SEXUAL=4\n",
    "CONTENT_SAFETY_THRESHOLD_VIOLENCE=4\n",
    "\n",
    "# Input/Output filtering\n",
    "CONTENT_SAFETY_BLOCK_UNSAFE_INPUT=true\n",
    "CONTENT_SAFETY_FILTER_UNSAFE_OUTPUT=true\n",
    "\n",
    "# Output action: \"redact\", \"placeholder\", \"empty\"\n",
    "CONTENT_SAFETY_OUTPUT_ACTION=redact\n",
    "CONTENT_SAFETY_PLACEHOLDER_TEXT=[Content removed due to safety policy]\n",
    "```\n",
    "\n",
    "## Matching .NET Structure\n",
    "\n",
    "This Python implementation mirrors the .NET Content Safety structure:\n",
    "- ‚úÖ Same API endpoints (/safety/scan-text, /safety/scan-image)\n",
    "- ‚úÖ Same response format (isSafe, highestSeverity, categorySeverities)\n",
    "- ‚úÖ Same severity scale (0-6)\n",
    "- ‚úÖ Automatic filtering in chat API\n",
    "- ‚úÖ Configurable thresholds and actions\n",
    "\n",
    "## Next Steps\n",
    "- Try the **Memory Demo** (04-LongRunningMemory-Demo.ipynb) to learn about session management\n",
    "- Explore the **Single Agent Demo** (01-SingleAgent-Demo.ipynb) for basic agent interaction\n",
    "- Check out the **Multiple Agents Demo** (02-MultipleAgents-Demo.ipynb) for group chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
