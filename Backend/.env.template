# ── Azure OpenAI ────────────────────────────────────────
AZURE_OPENAI_ENDPOINT="https://your-azure-openai-resource.openai.azure.com"
AZURE_OPENAI_DEPLOYMENT_NAME="gpt-4o"
AZURE_OPENAI_API_KEY="your-azure-openai-api-key-here"
AZURE_OPENAI_API_VERSION="2024-10-21"

# ── Agent Settings ────────────────────────────────────
# Enable long-running memory with UserInfoMemory (tracks user name and persona)
ENABLE_LONG_RUNNING_MEMORY="true"

# ── Azure AI Foundry (existing project) ────────────────
MS_FOUNDRY_PROJECT_ENDPOINT="https://your-ai-foundry-project.services.ai.azure.com/api/projects/your-project-name"
MS_FOUNDRY_AGENT_ID="asst_xxxxxxxxxxxxxxxxxxxxx"
MANAGED_IDENTITY_CLIENT_ID=""

# ?? Application Insights (Optional) ???????????????????????????????????????
# For observability and telemetry tracking
# Get connection string from Azure Portal -> Application Insights -> Properties
APPLICATIONINSIGHTS_CONNECTION_STRING=""

# ── Azure Content Safety (RECOMMENDED FOR PRODUCTION) ──────────────
# Create Content Safety resource in Azure Portal: https://portal.azure.com
# Endpoint format: https://<resource-name>.cognitiveservices.azure.com/
CONTENT_SAFETY_ENDPOINT="https://your-content-safety-resource.cognitiveservices.azure.com/"
CONTENT_SAFETY_API_KEY="your-content-safety-api-key-here"

# Master on/off switch
CONTENT_SAFETY_ENABLED="true"

# Global default severity threshold (0-7); used if per-category thresholds not provided
# 0-1: No concerns | 2-3: Low risk | 4-5: Medium risk (default) | 6-7: High risk
CONTENT_SAFETY_SEVERITY_THRESHOLD="4"

# Per-category reject thresholds (use -1 to disable a category)
# Each category can have its own threshold for fine-grained control
CONTENT_SAFETY_THRESHOLD_HATE="4"
CONTENT_SAFETY_THRESHOLD_SELFHARM="4"
CONTENT_SAFETY_THRESHOLD_SEXUAL="4"
CONTENT_SAFETY_THRESHOLD_VIOLENCE="4"

# Behavior Configuration
CONTENT_SAFETY_BLOCK_UNSAFE_INPUT="true"        # Block unsafe user input before agents run
CONTENT_SAFETY_FILTER_UNSAFE_OUTPUT="true"      # Filter/redact unsafe agent output

# Optional: Comma-separated blocklist names created in Content Safety Studio
# Create blocklists at: https://contentsafety.cognitive.azure.com/
CONTENT_SAFETY_BLOCKLISTS=""

# Output filtering action when content is unsafe (default: redact)
# Options: redact | placeholder | empty
CONTENT_SAFETY_OUTPUT_ACTION="redact"

# Replacement text when placeholder action is chosen
CONTENT_SAFETY_PLACEHOLDER_TEXT="[Content removed due to safety policy]"

# Application Configuration
FRONTEND_URL="http://localhost:3001"

# ?? AWS Configuration (Optional) ??????????????????????????????????????????
AWS_ACCESS_KEY_ID=""
AWS_SECRET_ACCESS_KEY=""
AWS_REGION="us-east-1"
AWS_BEDROCK_MODEL_ID="amazon.nova-pro-v1:0"
AWS_BEDROCK_AGENT_ID=""

# ?? Google Configuration (Optional) ???????????????????????????????????????
GOOGLE_API_KEY=""
GOOGLE_GEMINI_MODEL_ID="gemini-2.0-flash"

#OPENAI
OPENAI_API_KEY=""
OPENAI_MODEL_ID="gpt-4.1"